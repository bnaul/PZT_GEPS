{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Brett: invertible reshaping (spatial/temporal)\n",
    "- Brett: refactor model code into Python library\n",
    "- Josh: simple PCA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "gpu_opts = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4))\n",
    "K.set_session(tf.Session(config=gpu_opts))\n",
    "#K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autoencoder import load_data\n",
    "\n",
    "#X = load_data('data/cleaned_data.mat', resample_size=256)\n",
    "X = np.load('data/X_256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "model = keras.models.load_model('log/lstm128_x1_emb008_3m04_drop0_batch1024/weights.h5')\n",
    "\n",
    "encode_model = keras.models.Model(inputs=model.input,\n",
    "                                  outputs=[l for l in model.layers\n",
    "                                           if isinstance(l, keras.layers.core.Dense)][0].output)\n",
    "#inds = np.arange(20, X.shape[0], 40)\n",
    "inds = np.arange(X.shape[0])\n",
    "#encoding = encode_model.predict(X[inds])\n",
    "encoding = np.load('log/lstm128_x1_emb008_3m04_drop0_batch1024/encoding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(16)\n",
    "pca_model.fit(X.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fft = np.fft.rfft(X.squeeze())\n",
    "X_fft[:, 5:-4] = 0.  # x_fft[:, 0:5] (both real and imaginary) are the features\n",
    "X_fft_re = np.fft.irfft(X_fft)  # reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = np.random.randint(0, X.shape[0])\n",
    "#i = 20\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.plot(model.predict(X[[i]])[0])\n",
    "plt.plot(pca_model.inverse_transform(pca_model.transform(X[[i]].squeeze())[0]))\n",
    "plt.plot(X_fft_re[i])\n",
    "mse_rnn = np.mean((X[i] - model.predict(X[[i]])[0]) ** 2)\n",
    "mse_pca = np.mean((X[i].squeeze() - pca_model.inverse_transform(pca_model.transform(X[[i]].squeeze())[0])) ** 2)\n",
    "mse_fft = np.mean((X[i].squeeze() - X_fft_re[i]) ** 2)\n",
    "#plt.plot(X[i] - model.predict(X[[i]])[0])\n",
    "plt.legend(['Data', 'RNN', 'PCA', 'FFT'])\n",
    "plt.title(f\"i={i}; MSE (RNN)={mse_rnn:1.5f}; MSE (PCA)={mse_pca:1.5f}; MSE (FFT)={mse_fft:1.5f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadings = pca_model.transform(X.squeeze())[inds]\n",
    "fig, ax = plt.subplots(8, 2, figsize=(8, 36))\n",
    "for j in range(encoding.shape[1]):\n",
    "    ax[j, 0].imshow(encoding[:, j].reshape((256, 256)), cmap='viridis')#, vmin=encoding.min(), vmax=encoding.max())\n",
    "    ax[j, 1].imshow(loadings[:, j].reshape((256, 256)), cmap='viridis')#, vmin=encoding.min(), vmax=encoding.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e20 = encoding[20]\n",
    "Y20 = model.predict(X[[20]])\n",
    "plt.plot(decode_model.predict(e20[np.newaxis, :]).squeeze())\n",
    "plt.plot(Y20.squeeze() + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "VoltageData = scipy.io.loadmat('voltage_vector.mat')['BE_wave'].squeeze()\n",
    "V = scipy.signal.resample(VoltageData, 40 * 128 * 2)\n",
    "plt.plot(V[:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmin(np.sum(np.abs(encoding), axis=1))\n",
    "encoding[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.zeros((1, 8))\n",
    "#x[0] = 0.\n",
    "plt.plot(V[:256], decode_model.predict(encoding[i:i+1]).squeeze())\n",
    "plt.plot(V[:256], X[i].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_decoder(model, layer=keras.layers.LSTM, size=128, embedding=8, num_layers=1):\n",
    "    if num_layers > 1:\n",
    "        raise NotImplementedError(\"TODO >1 layer\")\n",
    "        \n",
    "    decode_model = keras.models.Sequential()\n",
    "    decode_model.add(keras.layers.RepeatVector(X.shape[1], input_shape=(embedding,)))\n",
    "    decode_model.add(keras.layers.Bidirectional(layer(size, return_sequences=True)))\n",
    "    decode_model.add(keras.layers.TimeDistributed(keras.layers.Dense(1, activation='linear')))\n",
    "    decode_model.set_weights(model.get_weights()[-len(decode_model.get_weights()):])\n",
    "\n",
    "    return decode_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b71549e4df4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model = conv_auto(32, 4, 8, n_step=X.shape[1],\n\u001b[0;32m----> 5\u001b[0;31m                   kernel_size=3, drop_frac=0.)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PZT_GEPS/autoencoder.py\u001b[0m in \u001b[0;36mconv_auto\u001b[0;34m(size, num_layers, embedding, n_step, kernel_size, drop_frac, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         model.add(Conv1D(size, kernel_size, padding='same', activation='relu'),\n\u001b[0;32m---> 59\u001b[0;31m                   input_shape=(n_step, 1) if i == 0 else None)\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "from autoencoder import conv_auto\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = conv_auto(32, 4, 8, n_step=X.shape[1],\n",
    "                  kernel_size=3, drop_frac=0.)\n",
    "model.compile(Adam(1e-4), loss='mse')\n",
    "\n",
    "history = model.fit(X, X, epochs=1, batch_size=64,\n",
    "                    callbacks=[TQDMCallback(),\n",
    "#                               TensorBoard(log_dir=log_dir, write_graph=False),\n",
    "#                               ModelCheckpoint(weights_path)],\n",
    "                              ],\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('log/lstm128_x1_emb008_3m04_drop0_batch1024/encoding.npy', encoding, allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "01d80a94a7bd4cc7a916bff791bb5227": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "04726251a614400e9992ac47d78d7138": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0fa460a36cc3405ba988b004706e3209": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1bc7ebb230f749f99823d205baf3aaa4": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1f447d5925d2469685e6eeb8572ee352": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1ffce5dc74d04cad92b78e3e35c5ebdd": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "2e61ef3667c54743a6b5f297798949f8": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "3d844e69560849c9b1a01cd3a2e0b20b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "3fa53d0dd06a4f8eb4d4214e644dc989": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "40d328ae60f3457aa969e222eefdca9b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4a429836075a47158543eaed8890c325": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "4ad4db4525944672990fe2d88320a1d7": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4bdeced5c3f24a28876ccca9f5a871c9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "590f26a8fe174866b459ebb7f0d7d506": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "75185f96e55145e0bad79769c9448c59": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "7ae8a6769d2843d18a5da6cfc4f44d0d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "7c6e0b4db5634e9a95ff2088a031d342": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "827951ac8e194336baabd26cbae6e2ad": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "8432cb6d475d4ef6b034c502dcbb6bab": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "8551d19cc717482b8415ab4bcf83476b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "87c4ad06f0164efeb2f18d9b797c38a2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "8a6260b8e19940dfa572d4d9eb6c7432": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "abfb5dc5cfcd46a283574936a3ad845f": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "aeca61d14a2c4a3fa4dbfef4a51f4cf0": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b4f86e0a27804471aabc7bfd782b0146": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "b6a4e41d6ca74b66a222dee9ff34d5b5": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b6c93ec60eeb4fc2913f681e2102d3dd": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b702c448aa2b4f8bb953d23c73d7a159": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c2415b89979a4dc18f9de6b7610d32db": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c584548159bb4f539f95e1a6d360e6f2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c9f2b7d3f3954970bf0c31a7943e9db1": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "ce1f3386eade43f29fd2162c4584fab1": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d1405a2fac264cb598db9675508c7584": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d1edd9a2ea854c959eee0235221878b4": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d44874015d5b4f71a7486510921dbbd6": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d6a19a688e794345a00663aafdefa55c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f3d3a8a5f4124a62b0e6c29fd9a51ce7": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f55a60bea6d645b097ea044401b586cc": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f803651a463447b4b10baa0691466099": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
